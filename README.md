# ðŸ“˜ Continual Learning: A Systematic Literature Review  
[![DOI](https://img.shields.io/badge/DOI-10.1016%2Fj.neunet.2025.108226-blue)](https://doi.org/10.1016/j.neunet.2025.108226)


This repository provides structured materials, analysis, and curated literature for our paper  
[*Continual Learning: A Systematic Literature Review* (*Neural Networks*, 2026)](https://doi.org/10.1016/j.neunet.2025.108226).


---

## ðŸ“‘ Table of Contents
- [1. ðŸ“‘ Manuscript Framework](#1-manuscript-framework)
- [2. ðŸ“š Citation](#2-citation)
- [3. ðŸ“˜ Awesome Continual Learning](#3-awesome-continual-learning)
- [4. ðŸ§¾ License](#4-license)
---

## 1. Manuscript Framework 

### 1. Introduction
Introduces the topic of continual learning (CL) and its importance in dynamic environments. This section defines key concepts and outlines the motivation, purpose, and scope of the review.

### 2. Preliminaries
Provides theoretical foundations and a brief historical overview of CL.

### 3. Systematic Literature Review (SLR) Methodology
Describes the SLR approach, including five research questions, literature search strategy, and inclusion/exclusion criteria. The study selection process yielded a final set of approximately 80 relevant papers (2010â€“2025) for in-depth review.

### 4. Review Findings

#### â€¢ Core Challenges in CL
Outlines the primary challenges that continual learning methods seek to address.

#### â€¢ Learning methods for CL
Organized into five main categories, further refined into 12 subcategories and 24 subaspects. For each subaspect, we listed the relevant literature and systematically analyzed representative methods, visualized through structured diagrams to highlight methodological distinctions and interconnections.

#### â€¢ Settings for CL
Systematic classification into three major classes, further detailed into 12 setting types. For each type, we listed the relevant literature and synthesized key studies, addressing conceptual ambiguities and literature coverage gaps identified in previous reviews.

#### â€¢ Evaluation Metrics
Reviews the metrics and benchmarks used to evaluate CL performance and discusses their significance and limitations.

### 5. Discussion
Synthesizes the implications, applications, and emerging research frontiers of CL.

#### â€¢ Real-world applications of CL
Summarizes CL use cases across seven domains, including computer vision, NLP, robotics, and digital twins.

#### â€¢ Future Directions
Emerging research directions include continual pretraining, task-free continual learning, efficient memory-augmented replay, and unified benchmarking â€” among eight key future directions.

### 6. Conclusion
Summarizes key contributions: a comprehensive 2010â€“2025 review, refined taxonomies, theoretical synthesis of forgetting, and an open-source repository.

---

## 2. Citation
If you use this repository or the paper list, please cite:
```
Qinwen Yang, Liyuan Wang, Joerg Wicker, Gillian Dobbie,
Continual learning: A systematic literature review,
Neural Networks,
Volume 195,
2026,
108226,
ISSN 0893-6080,
https://doi.org/10.1016/j.neunet.2025.108226.
(https://www.sciencedirect.com/science/article/pii/S0893608025011074)
```

##  3. Awesome Continual Learning

This is the paper list of our paper [_Continual Learning: A Systematic Literature Review_](https://kwnsfk27.r.eu-west-1.awstrack.me/L0/https:%2F%2Fdoi.org%2F10.1016%2Fj.neunet.2025.108226/1/0102019a4583e05e-26451b17-b991-4801-b4e9-0b375bf97a80-000000/X8PcNMUoHWw2at9pna0TacCUWaE=450). 

This repository covers a wide range of continual learning papers published from 2011 to the present and will provide all paper links and released code links to help researchers interested in this area and continue to add useful resources to this repo.

All data are sourced from Google Scholar. However, the 'cites/year' values for most papers were calculated based on citation data accessed in 2024. We will continue to update the data regularly in this repo.


| NO. |Title| Venue| Year | code | cites/year |
|-----|:------------------------------------------------------------------------------------------------------------------------------------:|:--------:|:----:|------|------------|
| 1| Towards Lifelong Learning of Large Language Models A Survey | CSUR | 2025|| 15|
| 2| Recent Advances of Foundation Language Models-based Continual Learning A Survey| CSUR | 2025|| 10|
| 3| Knowledge Decoupling via Orthogonal Projection for Lifelong Editing of Large Language Models| ACL | 2025|| 0|
| 4| Serial Lifelong Editing via Mixture of Knowledge Expert| ACL | 2025|| 0|
| 5| Efficient Domain Continual pretraining by Mitigating the Stability Gap| ACL | 2025|| 0|
| 6| Neuron-Level Sequential Editing for Large Language Models| ACL | 2025| [code](https://github.com/jianghoucheng/NSE)| 0|
| 7| Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models| ACL | 2025| [code](https://github.com/sutakori/CLoRA)| 0|
| 8| HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Large Multimodal Models| ACL | 2025| [code](https://github.com/Ghy0501/HiDe-LLaVA)| 0|
| 9| Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling| ACL | 2025|| 0|
| 10| Continual Gradient Low-Rank Projection Fine-Tuning for LLMs| ACL | 2025| [code](https://github.com/Wcxwcxw/GORP)| 0|
| 11| A Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning| ACL | 2025| [code](https://github.com/zyzhang11/DGAR)| 0|
| 12| Learn to Memorize: Scalable Continual Learning in Semiparametric Models with Mixture-of-Neighbors Induction Memory| ACL | 2025| [code](https://github.com/viniferagy/MoNIM)| 0|
| 13| Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning| ACL | 2025|| 0|
| 14| Recurrent Knowledge Identification and Fusion for Language Model Continual Learning| ACL | 2025| [code](https://github.com/WoodScene/Recurrent_KIF)| 0|
| 15| TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining| ACL | 2025| [code](https://github.com/apple/ml-tic-lm)| 0|
| 16| Exploiting Presentative Feature Distributions for Parameter-Efficient Continual Learning of Large Language Models| ICML | 2025| [code](https://github.com/ZERO-9215/Online-CL-LLMs)| 0|
| 17| Towards Understanding Catastrophic Forgetting in Two-layer Convolutional Neural Networks| ICML | 2025|| 0|
| 18| Predicting the Susceptibility of Examples to Catastrophic Forgetting| ICML | 2025|| 0|
| 19| Tensor Decomposition Based Memory-Efficient Incremental Learning| ICML | 2025|| 0|
| 20| Navigating Semantic Drift in Task-Agnostic Class-Incremental Learning| ICML | 2025| [code](https://github.com/fwu11/MACIL.git)| 0|
| 21| Componential Prompt-Knowledge Alignment for Domain Incremental Learning| ICML | 2025| [code](https://github.com/zhoujiahuan1991/ICML2025-KA-Prompt)| 0|
| 22| LADA: Scalable Label-Specific CLIP Adapter for Continual Learning| ICML | 2025| [code](https://github.com/MaolinLuo/LADA)| 0|
| 23| Reinforced Lifelong Editing for Language Models| ICML | 2025| [code](https://github.com/zhrli324/RLEdit)| 0|
| 24| Geometric Feature Embedding for Effective 3D Few-Shot Class Incremental Learning| ICML | 2025| [code](https://github.com/lixiangqi707/3D-FLEG)| 0|
| 25| Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts| ICML | 2025|| 0|
| 26| Unlocking the Power of Rehearsal in Continual Learning: A Theoretical Perspective| ICML | 2025|| 0|
| 27| Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models without Forgetting| ICML | 2025|| 0|
| 28| Mitigating Plasticity Loss in Continual Generalized Category Discovery| ICML | 2025| [code](https://github.com/bluecontra/C-CHAIN)| 0|
| 29| A Selective Learning Method for Temporal Concept Drift in Online Continual Learning| ICML | 2025|| 0|
| 30| Continual Reinforcement Learning by Planning in a Scale-Free World Model| ICML | 2025|| 0|
| 31| Label shift-based Continual Adversarial Defense for Open Environment| ICML | 2025|| 0|
| 32| Detection-guided Continual Representation Learning under Negative Transfer| ICML | 2025|| 0|
| 33| Probabilistic Group Mask Guided Discrete Optimization for Continual Learning| ICML | 2025| [code](https://github.com/njustkmg/ICML25-PGM)| 0|
| 34| Large Continual Instruction Assistant| ICML | 2025| [code](https://github.com/JingyangQiao/CoIN)| 0|
| 35| TreeLoRA: Efficient Continual Learning via Hierarchical LoRA Tree| ICML | 2025|| 0|
| 36| Upweighting Easy Samples in Fine-Tuning Mitigates Catastrophic Forgetting| ICML | 2025|| 0|
| 37| Language Guided Concept Bottleneck Models for Interpretable Continual Learning| CVPR | 2025| [code](https://github.com/FisherCats/CLG-CBM)| 0|
| 38| Dynamic Integration of Task-Specific Adapters for Class Incremental Learning| CVPR | 2025|| 0|
| 39| Towards Continual Universal Segmentation| CVPR | 2025|| 0|
| 40| Activating Sparse Part Concepts for 3D Class Incremental Learning| CVPR | 2025| [code](https://github.com/zhenyatian/ILPC)| 0|
| 41| Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation| CVPR | 2025|| 0|
| 42| CL-LoRA: Continual Low-Rank Adaptation for Rehearsal-Free Class-Incremental Learning| CVPR | 2025| [code](https://github.com/JiangpengHe/CL-LoRA)| 0|
| 43| CoMBO: Conflict Mitigation via Branched Optimization for Class Incremental Segmentation| CVPR | 2025| [code](https://guangyu-ryan.github.io/CoMBO)| 0|
| 44| BiLoRA: Almost-orthogonal Parameter Spaces for Continual Learning| CVPR | 2025| [code](https://github.com/yifeiacc/BiLoRA)| 0|
| 45| Attraction Diminishing and Distributing for Few-Shot Class-Incremental Learning| CVPR | 2025|| 0|
| 46| Incremental Object Keypoint Learning| CVPR | 2025|| 0|
| 47| Confidence-aware Replay-free Continual Lane Detection| CVPR | 2025|| 0|
| 48| Non-binary Nearest Class Mean classifier: Learnable Class Relationship Constraints for Incremental Learning| CVPR | 2025|| 0|
| 49| Multi-View Diversity-guided Exemplar Selection for Class-Incremental Learning| CVPR | 2025|| 0|
| 50| Balancing Performance and Adaptation in Federated Class-Incremental Learning| CVPR | 2025|| 0|
| 51| A Dual Memory Framework with Second-Order Consistency for Deeper Continual Bayesian Inference| CVPR | 2025|| 0|
| 52| TuB: Two-block Balanced Prompt for Continual Learning| CVPR | 2025|| 0|
| 53| LoRA-E: Effificiently Bridging Level-gap for Class Incremental Learning under Long-Stream Scenarios| CVPR | 2025|| 0|
| 54| Multi-point Adapter: Efficient Dynamic Expansion Framework for Class-Incremental Learning| CVPR | 2025|| 0|
| 55| Prototype Feature Filtering with Smoothness-Aware Reinitialisation for Class-Incremental Learning| CVPR | 2025|| 0|
| 56| Prototype-temporal Prompt Tuning for Continual Video Relationship Detection| CVPR | 2025|| 0|
| 57| A Multi-subtask Cooperative Wasserstein-aligned Feature for Incremental Learning| CVPR | 2025|| 0|
| 58| LVEL: Label Value Enhanced Representation Learning with One Example per Novel Class| CVPR | 2025|| 0|
| 59| Injecting Continual Learning Capability into Pretrained Object Detector via Dansuos Libraries| CVPR | 2025|| 0|
| 60| BiMC: Mitigating Catastrophic Forgetting via Bidirectional Modulator with Consistent Multi-Level Constraints| CVPR | 2025| [code](https://github.com/yychen016/BiMC)| 0|
| 61| Reducing Class-wise Confusion for Incremental Learning with Disentangled Manifolds| CVPR | 2025| [code](https://github.com/lilyht/CREATE)| 0|
| 62| ProtoDepth: Unsupervised Continual Depth Completion with Prototypes| CVPR | 2025| [code](https://github.com/patrickqrim/ProtoDepth)| 0|
| 63| Beyond Background Shift: Rethinking Instance Replay in Continual Semantic Segmentation| CVPR | 2025| [code](https://github.com/YikeYin97/EIR)| 0|
| 64| Do Your Best and Get Enough Rest for Continual Learning| CVPR | 2025| [code](https://github.com/hankyul2/ViewBatchModel)| 0|
| 65| Task-Agnostic Guided Feature Expansion for Class-Incremental Learning| CVPR | 2025| [code](https://github.com/bwnzheng/TagFex_CVPR2025)| 0|
| 66| ConceptGuard: Continual Personalized Text-to-Image Generation with Forgetting and Confusion Mitigation| CVPR | 2025|| 0|
| 67| Synthetic Data is an Elegant GIFT for Continual Vision-Language Models| CVPR | 2025| [code](https://github.com/Luo-Jiaming/GIFT_CL)| 0|
| 68| Rethinking Query-based Transformer for Continual Image Segmentation| CVPR | 2025| [code](https://github.com/SooLab/SimCIS)| 0|
| 69| Boosting Domain Incremental Learning: Selecting the Optimal Parameters is All You Need| CVPR | 2025| [code](https://github.com/qwangcv/SOYO)| 0|
| 70| Order-Robust Class Incremental Learning: Graph-Driven Dynamic Similarity Grouping| CVPR | 2025| [code](https://github.com/AIGNLAI/GDDSG)| 0|
| 71| Adapter Merging with Centroid Prototype Mapping for Scalable Class-Incremental Learning| CVPR | 2025| [code](https://github.com/tf63/ACMap)| 0|
| 72| AVQACL: A Novel Benchmark for Audio-Visual Question Answering Continual Learning| CVPR | 2025| [code](https://github.com/kx-wu/CVPR2025_AVQACL)| 0|
| 73| Handling Spatial-Temporal Data Heterogeneity for Federated Continual Learning via Tail Anchor| CVPR | 2025| [code](https://github.com/SkyOfBeginning/FedTA_CVPR2025)| 0|
| 74| One-for-More: Continual Diffusion Model for Anomaly Detection| CVPR | 2025|| 0|
| 75| Sorry, Still on the Way: Enforcing Diversity and Performance in Learning Next in Continual Image Classification| CVPR | 2025| [code](https://github.com/NeurAI-Lab/STL-CVPR2025)| 0|
| 76| Continual Domain Adaptation with Multiple Labeled Target Domains based Generative Replay| CVPR | 2025|| 0|
| 77| Runtime Logic Injection for Dynamic Backdoor Defense in Continual Learning| CVPR | 2025|| 0|
| 78| H2M-Net: Hierarchical Human Memory Network for Robust Continual Referring Expression Comprehension| CVPR | 2025|| 0|
| 79| Target-oriented Knowledge Modelling for Task-Incremental Dense Scene Understanding| CVPR | 2025|| 0|
| 80| Multi-Task Consistent Replay for Online Continual Learning| CVPR | 2025|| 0|
| 81| Past-Future-guided Redundancy Filtering for Class-Incremental Learning| CVPR | 2025|| 0|
| 82| Overcoming Negative Pretraining for Class-incremental Learning| CVPR | 2025|| 0|
| 83| Prevalence of Negative Transfer in Continual Learning-based Deep 3D Object Detection| CVPR | 2025| [code](https://github.com/hongjoon0805/Reset-Distill.git)| 0|
| 84| Adapt-$\infty$: Scalable Continual Multimodal Adaptation via Iterative Schema Registration| ICLR | 2025| [code](https://github.com/adymaharana/adapt-inf)| 0|
| 85| Learning Continually by Spectral Regularization| ICLR | 2025|| 0|
| 86| Self-Normalized Resets for Plasticity in Continual Learning| ICLR | 2025| [code](https://github.com/ajozefiak/SelfNormalizedResets)| 0|
| 87| PseDet: Revisiting the Power of Pseudo Labels for Class-Incremental Object Detection| ICLR | 2025| [code](https://github.com/wang-qiuchen/PseDet)| 0|
| 88| Meta-Continual Learning of Neural Fields| ICLR | 2025| [code](https://github.com/seungyoon-woo/MCL-NF)| 0|
| 89| Vision and Language Synergy for Rehearsal-free Continual Low-Shot Learning| ICLR | 2025| [code](https://github.com/anwarmaxsum/LEAPGEN)| 0|
| 90| Advancing Prompt-based Methods for Replay-free Class Incremental Learning through Multi-Level Interactive Adaptation| ICLR | 2025| [code](https://github.com/kangzhiq/MISA)| 0|
| 91| LoRA Subtraction for Drift-Resistant Space in Continual Learning| TPAMI | 2025| [code](https://github.com/scarlet0703/LoRA-Sub-DRS)| 0|
| 92| KAC: Kolmogorov-Arnold Classifier for Continual Learning| TPAMI | 2025| [code](https://github.com/Ethanhuhuhu/KAC)| 0|
| 93| HiDe-PET: Continual Learning via Hierarchical Decoupling for Reduced Forgetting| TPAMI | 2025|| 0|
| 94| Adaptive Score Alignment Learning for Continual Perceptual Question Answering| VR-TVCG | 2025| [code](https://github.com/ZhouKanglei/ASAL_CVQA)| 0|
| 95| A Comprehensive Survey of Continual Learning: Theory, Method and Application| TPAMI| 2024|| 851 |
| 96| Continual Learning with Pre-Trained Models: A Survey| IJCAI | 2024|[code](https://github.com/sun-hailong/LAMDA-PILOT)| 75|
| 97| Elastic Feature Consolidation For Cold Start Exemplar-Free Incremental Learning| ICLR | 2024| [code](https://github.com/simomagi/elastic_feature_consolidation) | 0|
| 98| Function-space Parameterization of Neural Networks for Sequential Learning| ICLR | 2024|| 0|
| 99| Progressive Fourier Neural Representation for Sequential Video Compilation| ICLR | 2024|| 0|
| 100| Kalman Filter Online Classification from non-Stationary Data| ICLR | 2024|| 0|
| 101| Continual Momentum Filtering on Parameter Space for Online Test-time Adaptation| ICLR | 2024|| 0|
| 102 | TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models | ICLR | 2024|| 0|
| 103 | Class Incremental Learning via Likelihood Ratio Based Task Prediction| ICLR | 2024| [code](https://github.com/linhaowei1/TPL)| 1|
| 104 | The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting - An Analytical Model| ICLR | 2024|| 2|
| 105 | Prediction Error-based Classification for Class-Incremental Learning | ICLR | 2024| [code](https://github.com/michalzajac-ml/pec)| 3|
| 106 | Adapting Large Language Models via Reading Comprehension| ICLR | 2024| [code](https://github.com/microsoft/LMOps/tree/main/adaptllm) | 16|
| 107 | Accurate Forgetting for Heterogeneous Federated Continual Learning | ICLR | 2024|| 0|
| 108 | Fixed Non-negative Orthogonal Classifier: Inducing Zero-mean Neural Collapse with Feature Dimension Separation | ICLR | 2024|| 0|
| 109 | A Probabilistic Framework for Modular Continual Learning| ICLR | 2024|| 0|
| 110 | A Unified and General Framework for Continual Learning| ICLR | 2024|| 0|
| 111 | Continual Learning on a Diet: Learning from Sparsely Labeled Streams Under Constrained Computation| ICLR | 2024|| 0|
| 112 | CPPO: Continual Learning for Reinforcement Learning with Human Feedback | ICLR | 2024|| 0|
| 113 | Online Continual Learning for Interactive Instruction Following Agents| ICLR | 2024| [code](https://github.com/snumprlab/cl-alfred)| 0|
| 114 | Scalable Language Model with Generalized Continual Learning | ICLR | 2024|| 0|
| 115 | ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation| ICLR | 2024|| 9|
| 116 | Hebbian Learning based Orthogonal Projection for Continual Learning of Spiking Neural Networks | ICLR | 2024| [code](https://github.com/pkuxmq/HLOP-SNN) | 0|
| 117 | TiC-CLIP: Continual Training of CLIP Models| ICLR | 2024|| 3|
| 118 | Continual Learning in the Presence of Spurious Correlations: Analyses and a Simple Baseline| ICLR | 2024|| 0|
| 119 | Addressing Catastrophic Forgetting and Loss of Plasticity in Neural Networks| ICLR | 2024|| 0|
| 120 | Locality Sensitive Sparse Encoding for Learning World Models Online| ICLR | 2024|| 0|
| 121 | Dissecting learning and forgetting in language model finetuning| ICLR | 2024|| 0|
| 122 | Prompt Gradient Projection for Continual Learning| ICLR | 2024| [code](https://github.com/JingyangQiao/prompt-gradient-projection)| 0|
| 123 | Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time| ICLR | 2024|| 0|
| 124 | Divide and not forget: Ensemble of selectively trained experts in Continual Learning| ICLR | 2024| [code](https://github.com/grypesc/SEED) | 1|
| 125 | Towards Continual Learning Desiderata via HSIC-Bottleneck Orthogonalization and Equiangular Embedding | AAAI | 2024|| 0|
| 126 | Fine-Grained Knowledge Selection and Restoration for Non-Exemplar Class Incremental Learning | AAAI | 2024|| 0|
| 127 | Task-aware information routing from common representation space in lifelong learning| ICLR | 2023|| 9|
| 128 | An empirical investigation of the role of pre-training in lifelong learning | JMLR | 2023|| 25|
| 129 | Progressive prompts: Continual learning for language models | ICLR | 2023|| 45|
| 130 | Task-balanced batch normalization for exemplar-based classincremental learning| CVPR | 2023|| 3|
| 131 | Introducing Language Guidance in Prompt-based Continual Learning | ICCV | 2023|| 9|
| 132 | Symbolic replay: Scene graph as prompt for continual learning on vqa task | AAAI | 2023|| 7.5 |
| 133 | CODA-Prompt: COntinual Decomposed Attention-Based Prompting for Rehearsal-Free Continual Learning| CVPR | 2023| [code](https://github.com/GT-RIPL/CODA-Prompt)| 37|
| 134 | Generating Instance-level Prompts for Rehearsal-free Continual Learning | ICCV | 2023|| 4|
| 135 | Decouple Before Interact: Multi-Modal Prompt Learning for Continual Visual Question Answering| ICCV | 2023|| 3|
| 136 | Lightweight Prompt Learning with General Representation for Rehearsal-free Continual Learning| NeurIPS | 2023|| 0.5 |
| 137 | When Prompt-based Incremental Learning Does Not Meet Strong Pretraining | ICCV | 2023|| 3|
| 138 | Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation| AAAI | 2023|| 40|
| 139 | Online Class Incremental Learning on Stochastic Blurry Task Boundary via Mask and Visual Prompt Tuning| ICCV | 2023|| 2|
| 140 | Loss Decoupling for Task-Agnostic Continual Learning| NeurIPS | 2023|| 2|
| 141 | Bilevel Coreset Selection in Continual Learning: A New Formulation and Algorithm | NeurIPS | 2023|| 0|
| 142 | Fairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments| NeurIPS | 2023|| 3|
| 143 | An Efficient Dataset Condensation Plugin and Its Application to Continual Learning | NeurIPS | 2023|| 0|
| 144 | Overcoming Recency Bias of Normalization Statistics in Continual Learning: Balance and Adaptation| NeurIPS | 2023|| 0|
| 145 | Prediction and Control in Continual Reinforcement Learning| NeurIPS | 2023|| 0|
| 146 | On the Stability-Plasticity Dilemma in Continual Meta-Learning: Theory and Algorithm| NeurIPS | 2023|| 0|
| 147 | Saving 100x Storage: Prototype Replay for Reconstructing Training Sample Distribution in Class-Incremental Semantic Segmentation | NeurIPS | 2023|| 1|
| 148 | A Data-Free Approach to Mitigate Catastrophic Forgetting in Federated Class Incremental Learning for Vision Tasks| NeurIPS | 2023|| 0|
| 149 | Few-Shot Class-Incremental Learning via Training-Free Prototype Calibration | NeurIPS | 2023|| 3|
| 150 | A Unified Approach to Domain Incremental Learning with Memory: Theory and Algorithm| NeurIPS | 2023| [code](https://github.com/Wang-ML-Lab/unified-continual-learning) | 2|
| 151 | Minimax Forward and Backward Learning of Evolving Tasks with Performance Guarantees| NeurIPS | 2023| [code](https://github.com/MachineLearningBCAM/IMRCs-for-incremental-learning-NeurIPS-2023) | 0|
| 152 | Recasting Continual Learning as Sequence Modeling| NeurIPS | 2023|| 2|
| 153 | Augmented Memory Replay-based Continual Learning Approaches for Network Intrusion Detection| NeurIPS | 2023|| 0|
| 154 | Does Continual Learning Meet Compositionality? New Benchmarks and An Evaluation Framework| NeurIPS | 2023|| 0|
| 155 | CL-NeRF: Continual Learning of Neural Radiance Fields for Evolving Scene Representation | NeurIPS | 2023|| 0|
| 156 | TriRE: A Multi-Mechanism Learning Paradigm for Continual Knowledge Retention and Promotion | NeurIPS | 2023|| 1|
| 157 | Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models| NeurIPS | 2023|| 17|
| 158 | A Definition of Continual Reinforcement Learning | NeurIPS | 2023|| 8|
| 159 | RanPAC: Random Projections and Pre-trained Models for Continual Learning| NeurIPS | 2023|| 5|
| 160 | Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality| NeurIPS | 2023|| 6|
| 161 | FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning | NeurIPS | 2023|| 1|
| 162 | The Ideal Continual Learner: An Agent That Never Forgets| ICML | 2023|| 12|
| 163 | Continual Learners are Incremental Model Generalizers | ICML | 2023|| 2|
| 164 | Learnability and Algorithm for Continual Learning| ICML | 2023| [code](https://github.com/k-gyuhak/CLOOD)| 12|
| 165 | Parameter-Level Soft-Masking for Continual Learning| ICML | 2023|| 8|
| 166 | Continual Learning in Linear Classification on Separable Data| ICML | 2023|| 6|
| 167 | DualHSIC: HSIC-Bottleneck and Alignment for Continual Learning | ICML | 2023|| 4|
| 168 | BiRT: Bio-inspired Replay in Vision Transformers for Continual Learning | ICML | 2023|| 9|
| 169 | DDGR: Continual Learning with Deep Diffusion-based Generative Replay | ICML | 2023|| 14|
| 170 | Neuro-Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and Concept Rehearsal | ICML | 2023|| 12|
| 171 | Theory on Forgetting and Generalization of Continual Learning| ICML | 2023|| 13|
| 172 | Poisoning Generative Replay in Continual Learning to Promote Forgetting | ICML | 2023|| 1|
| 173 | Continual Vision-Language Representation Learning with Off-Diagonal Information| ICML | 2023|| 8|
| 174 | Prototype-Sample Relation Distillation: Towards Replay-Free Continual Learning| ICML | 2023|| 4|
| 175 | Does Continual Learning Equally Forget All Parameters?| ICML | 2023|| 7|
| 176 | Self-regulating Prompts: Foundational Model Adaptation without Forgetting | ICML | 2023| [code](https://github.com/muzairkhattak/PromptSRC)| 22|
| 177 | Prototype Reminiscence and Augmented Asymmetric Knowledge Aggregation for Non-Exemplar Class-Incremental Learning| ICML | 2023| [code](https://github.com/ShiWuxuan/PRAKA) | 3|
| 178 | Tangent Model Composition for Ensembling and Continual Fine-tuning | ICML | 2023| [code](https://github.com/tianyu139/tangent-model-composition)||
| 179 | CBA: Improving Online Continual Learning via Continual Bias Adaptor| ICML | 2023|| 2|
| 180 | CTP: Towards Vision-Language Continual Pretraining via Compatible Momentum Contrast and Topology Preservation| ICML | 2023| [code](https://github.com/KevinLight831/CTP) | 7|
| 181 | NAPA-VQ: Neighborhood Aware Prototype Augmentation with Vector Quantization for Continual Learning| ICML | 2023| [code](https://github.com/TamashaM/NAPA-VQ.git) | 0|
| 182 | Online Continual Learning on Hierarchical Label Expansion | ICML | 2023|| 0|
| 183 | Class-Incremental Grouping Network for Continual Audio-Visual Learning| ICML | 2023| [code](https://github.com/stoneMo/CIGN) | 4|
| 184 | Rapid Adaptation in Online Continual Learning: Are We Evaluating It Right?| ICML | 2023| [code](https://github.com/drimpossible/EvalOCL) | 8|
| 185 | Online Class Incremental Learning on Stochastic Blurry Task Boundary via Mask and Visual Prompt Tuning| ICML | 2023| [code](https://github.com/moonjunyyy/si-blurry) | 2|
| 186 | Dynamic Residual Classifier for Class Incremental Learning| ICML | 2023|| 2|
| 187 | First Session Adaptation: A Strong Replay-Free Baseline for Class-Incremental Learning| ICML | 2023|| 8|
| 188 | Masked Autoencoders are Efficient Class Incremental Learners| ICML | 2023|| 4|
| 189 | CLNeRF: Continual Learning Meets NeRFs| ICML | 2023|| 2|
| 190 | Preventing Zero-Shot Transfer Degradation in Continual Learning of Vision-Language Models| ICML | 2023| [code](https://github.com/Thunderbeee/ZSCL)| 16|
| 191 | LFS-GAN: Lifelong Few-Shot Image Generation| ICML | 2023|| 1|
| 192| TARGET: Federated Class-Continual Learning via Exemplar-Free Distillation | ICML | 2023|| 3|
| 193| Learning to Learn: How to Continuously Teach Humans and Machines | ICML | 2023|| 1|
| 194| Audio-Visual Class-Incremental Learning | ICML | 2023| [code](https://github.com/weiguoPian/AV-CIL_ICCV2023)| 9|
| 195| MetaGCD: Learning to Continually Learn in Generalized Category Discovery| ICML | 2023|| 6|
| 196| Exemplar-Free Continual Transformer with Convolutions | ICML | 2023|| 3|
| 197| A Unified Continual Learning Framework with General Parameter-Efficient Tuning| ICML | 2023|| 14|
| 198| Incremental Generalized Category Discovery| ICML | 2023|| 10|
| 199| Heterogeneous Forgetting Compensation for Class-Incremental Learning | ICML | 2023| [code](https://github.com/JiahuaDong/HFC)| 6|
| 200| Augmented Box Replay: Overcoming Foreground Shift for Incremental Object Detection | ICML | 2023| [code](https://github.com/YuyangSunshine/ABR_IOD) | 3|
| 201| MRN: Multiplexed Routing Network for Incremental Multilingual Text Recognition| ICML | 2023| [code](https://github.com/simplify23/MRN)| 3|
| 202| CLR: Channel-wise Lightweight Reprogramming for Continual Learning | ICML | 2023| [code](https://github.com/gyhandy/Channel-wise-Lightweight-Reprogramming)| 0|
| 203| ICICLE: Interpretable Class Incremental Continual Learning| ICML | 2023|| 8|
| 204| Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery| ICML | 2023|| 4|
| 205| SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained Model | ICML | 2023| [code](https://github.com/GengDavid/SLCA)| 15|
| 206| Online Prototype Learning for Online Continual Learning | ICML | 2023| [code](https://github.com/weilllllls/OnPro)| 6|
| 207| Computationally Budgeted Continual Learning: What Does Matter? | CVPR | 2023|| 26|
| 208| Real-Time Evaluation in Online Continual Learning: A New Hope| CVPR | 2023|| 12|
| 209| Dealing With Cross-Task Class Discrimination in Online Continual Learning | CVPR | 2023| [code](https://github.com/gydpku/GSA) | 8|
| 210| Decoupling Learning and Remembering: A Bilevel Memory Framework With Knowledge Projection for Task-Incremental Learning | CVPR | 2023| [code](https://github.com/SunWenJu123/BMKP)| 3|
| 211| GKEAL: Gaussian Kernel Embedded Analytic Learning for Few-shot Class Incremental Task | CVPR | 2023|| 8|
| 212| EcoTTA: Memory-Efficient Continual Test-time Adaptation via Self-distilled Regularization| CVPR | 2023|| 31|
| 213| Endpoints Weight Fusion for Class Incremental Semantic Segmentation| CVPR | 2023|| 12|
| 214| On the Stability-Plasticity Dilemma of Class-Incremental Learning| CVPR | 2023|| 13|
| 215| Regularizing Second-Order Influences for Continual Learning | CVPR | 2023| [code](https://github.com/feifeiobama/InfluenceCL)| 5|
| 216| Rebalancing Batch Normalization for Exemplar-based Class-Incremental Learning | CVPR | 2023|| 5|
| 217| Task Difficulty Aware Parameter Allocation & Regularization for Lifelong Learning| CVPR | 2023|| 1|
| 218| A Probabilistic Framework for Lifelong Test-Time Adaptation | CVPR | 2023| [code](https://github.com/dhanajitb/petal) | 17|
| 219| Continual Semantic Segmentation with Automatic Memory Sample Selection| CVPR | 2023|| 13|
| 220| Exploring Data Geometry for Continual Learning | CVPR | 2023|| 1|
| 221| PCR: Proxy-based Contrastive Replay for Online Class-Incremental Continual Learning| CVPR | 2023| [code](https://github.com/FelixHuiweiLin/PCR)| 17|
| 222| Learning with Fantasy: Semantic-Aware Virtual Contrastive Constraint for Few-Shot Class-Incremental Learning | CVPR | 2023| [code](https://github.com/zysong0113/SAVC) | 16|
| 223| Foundation Model Drives Weakly Incremental Learning for Semantic Segmentation | CVPR | 2023|| 5|
| 224| Continual Detection Transformer for Incremental Object Detection | CVPR | 2023| [code](https://github.com/yaoyao-liu/CL-DETR)| 20|
| 225| PIVOT: Prompting for Video Continual Learning| CVPR | 2023|| 26|
| 226| Principles of Forgetting in Domain-Incremental Semantic Segmentation in Adverse Weather Conditions| CVPR | 2023|| 4|
| 227| Class-Incremental Exemplar Compression for Class-Incremental Learning| CVPR | 2023| [code](https://github.com/xfflzl/CIM-CIL)| 14|
| 228| Dense Network Expansion for Class Incremental Learning| CVPR | 2023|| 10|
| 229| Online Bias Correction for Task-Free Continual Learning | ICLR | 2023|| 10|
| 230| Sparse Distributed Memory is a Continual Learner | ICLR | 2023|| 8|
| 231| Continual pre-training of language models | ICLR | 2023|| 47|
| 232| Progressive Prompts: Continual Learning for Language Models without Forgetting| ICLR | 2023|| 45|
| 233| Is Forgetting Less a Good Inductive Bias for Forward Transfer? | ICLR | 2023|| 6|
| 234| Online Boundary-Free Continual Learning by Scheduled Data Prior| ICLR | 2023|| 6|
| 235| Incremental Learning of Structured Memory via Closed-Loop Transcription | ICLR | 2023|| 14|
| 236| Better Generative Replay for Continual Federated Learning | ICLR | 2023|| 16|
| 237| BEEF: Class-Incremental Learning via Efficient Energy-Based Expansion and Fusion | ICLR | 2023|| 21|
| 238| Progressive Voronoi Diagram Subdivision Enables Accurate Data-free Class-Incremental Learning| ICLR | 2023|| 8|
| 239| Learning without Prejudices: Continual Unbiased Learning via Benign and Malignant Forgetting | ICLR | 2023|| 3|
| 240| Building a Subspace of Policies for Scalable Continual Learning| ICLR | 2023|| 15|
| 241| A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning | ICLR | 2023|| 51|
| 242| Continual Unsupervised Disentangling of Self-Organizing Representations | ICLR | 2023|| 1|
| 243| Warping the Space: Weight Space Rotation for Class-Incremental Few-Shot Learning | ICLR | 2023|| 10|
| 244| Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class-Incremental Learning| ICLR | 2023|| 47|
| 245| On the Soft-Subnetwork for Few-Shot Class Incremental Learning | ICLR | 2023|| 6|
| 246| Error Sensitivity Modulation based Experience Replay: Mitigating Abrupt Representation Drift in Continual Learning | ICLR | 2023|| 9|
| 247| Sparse Coding in a Dual Memory System for Lifelong Learning | AAAI | 2023| [code](https://github.com/NeurAI-Lab/SCoMMER)| 7|
| 248| A Comprehensive Survey of Forgetting in Deep Learning Beyond Continual Learning| Arxiv| 2023|| 9|
| 249| Deep Class-Incremental Learning: A Survey | Arxiv| 2023|| 74|
| 250| Continual Learning: Applications and the Road Forward | Arxiv| 2023|| 4|
| 251| Forgetting to remember: A scalable incremental learning framework for cross-task blind image quality assessment| MM | 2023|||
| 252| Towards continual egocentric activity recognition: A multi-modal egocentric activity dataset for continual learning| MM | 2023|||
| 253| Cross-Modal Alternating Learning with Task-Aware Representations for Continual Learning | MM | 2023|||
| 254| Semantics-driven generative replay for few-shot class incremental learning| MM | 2023|||
| 255| Continual learning via sequential function-space variational inference| ICML | 2022|| 13.5|
| 256| Uncertainty-aware contrastive distillation for incremental semantic segmentation | PAMI | 2022|| 20|
| 257| Class-incremental learning with cross-space clustering and controlled transfer| ECCV | 2022| [code](https://github.com/ashok-arjun/CSCCT) | 9|
| 258| Class-incremental continual learning into the extended derverse| PAMI | 2022|| 39.5|
| 259| Continual pre-training of language models for math problem understanding with syntax-aware memory network | ACL| 2022|| 7.5 |
| 260| Energy-based latent aligner for incremental learning| CVPR | 2022| [code](https://github.com/JosephKJ/ELI) | 17|
| 261| Retrospective adversarial replay for continual learning | NeurIPS | 2022|| 7.5 |
| 262| Gcr: Gradient coreset based replay buffer selection for continual learning| CVPR | 2022|| 35|
| 263| Bring evanescent representations to life in lifelong class incremental learning| CVPR | 2022|| 10.5|
| 264| Foster: Feature boosting and compression for class-incremental learning | ECCV | 2022| [code](https://github.com/G-U-N/ECCV22-FOSTER)| 61|
| 265| Continual learning through retrieval and imagination| AAAI | 2022|| 11.5|
| 266| Self-sustaining representation expansion for non-exemplar class-incremental learning| CVPR | 2022|| 38.5|
| 267| Probing representation forgetting in supervised and unsupervised continual learning| CVPR | 2022|| 28.5|
| 268| Adaptive orthogonal projection for batch and online continual learning| AAAI | 2022|| 12.5|
| 269| Balancing stability and plasticity through advanced null space in continual learning| ECCV | 2022|| 11|
| 270| Towards better plasticity-stability trade-off in incremental learning: A simple linear connector | CVPR | 2022|| 12|
| 271| Beyond not-forgetting: Continual learning with backward knowledge transfer| NeurIPS | 2022|| 7|
| 272| Mimicking the oracle: An initial phase decorrelation approach for class incremental learning | CVPR | 2022| [code](https://github.com/Yujun-Shi/CwD)| 20|
| 273| Anti-retroactive interference for lifelong learning| ECCV | 2022|| 4.5 |
| 274| Class-incremental learning with strong pre-trained models | CVPR | 2022|| 23.5|
| 275| Transfer without forgetting | ECCV | 2022| [code](https://github.com/mbosc/twf)| 9.5 |
| 276| Memory efficient continual learning with transformers | NeurIPS | 2022|| 13|
| 277| Self-supervised models are continual learners| CVPR | 2022| [code](https://github.com/DonkeyShot21/cassle)| 50.5|
| 278| The challenges of continuous self-supervised learning | ECCV | 2022|| 14.5|
| 279| Dlcft: Deep linear continual fine-tuning for general incremental learning | ECCV | 2022|| 3.5 |
| 280| S-prompts learning with pre-trained transformers: An occamÃ¢â‚¬â„¢s razor for domain incremental learning| NeurIPS | 2022|| 50|
| 281| Meta-learning with less forgetting on large-scale non-stationary task distributions| ECCV | 2022|| 4|
| 282| Dualprompt: Complementary prompting for rehearsal-free continual learning | ECCV | 2022| [code](https://github.com/google-research/l2p)| 99|
| 283| Learning to prompt for continual learning | CVPR | 2022|| 174.5 |
| 284| Generative negative text replay for continual vision-language pretraining | ECCV | 2022|| 5|
| 285| Dytox: Transformers for continual learning with dynamic token expansion | CVPR | 2022|| 92|
| 286| Incremental task learning with incremental rank updates | ECCV | 2022|| 3|
| 287| Helpful or harmful: Intertask association in continual learning| ECCV | 2022|| 3.5 |
| 288| Forget-free continual learning with winning subnetworks | ICML | 2022|| 25|
| 289| Wide neural networks forget less catastrophically| ICLR | 2022|| 20.5|
| 290| Coscl: Cooperation of small continual learners is stronger than a big one | ECCV | 2022| [code](https://github.com/lywang3081/CoSCL)| 7|
| 291| Online Continual Learning through Mutual Information Maximization| ICML | 2022|| 37|
| 292| Prototype-guided continual adaptation for class-incremental unsupervised domain adaptation | ICML | 2022| [code](https://github.com/Hongbin98/ProCA) | 11|
| 293| Improving Task-free Continual Learning by Distributionally Robust Memory Evolution | ICML | 2022|| 15|
| 294| NISPA: Neuro-Inspired Stability-Plasticity Adaptation for Continual Learning in Sparse Networks| ICML | 2022|| 14.5|
| 295| A Theoretical Study on Solving Continual Learning| ICML | 2022| [code](https://github.com/k-gyuhak/WPTP)| 19|
| 296| ACIL: Analytic Class-Incremental Learning with Absolute Memorization and Privacy Protection| NeruIPS | 2022|| 2.5 |
| 297| Margin-Based Few-Shot Class-Incremental Learning with Class-Level Overfitting Mitigation| NeruIPS | 2022| [code](https://github.com/zoilsen/clom) | 9.5 |
| 298| Disentangling Transfer in Continual Reinforcement Learning| NeruIPS | 2022|| 9.5 |
| 299| Task-Free Continual Learning via Online Discrepancy Distance Learning| NeruIPS | 2022|| 9|
| 300| A simple but strong baseline for online continual learning: Repeated Augmented Rehearsal| NeruIPS | 2022|| 16|
| 301| Lifelong Neural Predictive Coding: Learning Cumulatively Online without Forgetting | NeruIPS | 2022|| 7|
| 302| Few-Shot Continual Active Learning by a Robot| NeruIPS | 2022|| 6.5 |
| 303| Continual learning: a feature extraction formalization, an efficient algorithm, and fundamental obstructions | NeruIPS | 2022|| 3.5 |
| 304| SparCL: Sparse Continual Learning on the Edge| NeruIPS | 2022|| 15|
| 305| CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks| NeruIPS | 2022| [code](https://github.com/GLAMOR-USC/CLiMB)| 18|
| 306| Continual Learning In Environments With Polynomial Mixing Times| NeruIPS | 2022| [code](https://github.com/sharathraparthy/polynomial-mixing-times)| 2.5 |
| 307| Exploring Example Influence in Continual Learning| NeruIPS | 2022| [code](https://github.com/sssunqing/example_influence_cl)| 12|
| 308| ALIFE: Adaptive Logit Regularizer and Feature Replay for Incremental Semantic Segmentation | NeruIPS | 2022|| 6|
| 309| On the Effectiveness of Lipschitz-Driven Rehearsal in Continual Learning| NeruIPS | 2022| [code](https://github.com/aimagelab/lider) | 11|
| 310| On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting| NeruIPS | 2022|| 11|
| 311| CGLB: Benchmark Tasks for Continual Graph Learning | NeruIPS | 2022| [code](https://github.com/QueuQ/CGLB) | 12|
| 312| How Well Do Unsupervised Learning Algorithms Model Human Real-time and Life-long Learning? | NeruIPS | 2022|| 8.5 |
| 313| Helpful or Harmful: Inter-Task Association in Continual Learning | ECCV | 2022|| 3.5 |
| 314| incDFM: Incremental Deep Feature Modeling for Continual Novelty Detection | ECCV | 2022|| 2.5 |
| 315| S3C: Self-Supervised Stochastic Classifiers for Few-Shot Class-Incremental Learning| ECCV | 2022|| 9.5 |
| 316| Online Task-free Continual Learning with Dynamic Sparse Distributed Memory| ECCV | 2022| [code](https://github.com/Julien-pour/Dynamic-Sparse-Distributed-Memory) | 5|
| 317| Balancing between Forgetting and Acquisition in Incremental Subpopulation Learning | ECCV | 2022|| 3.5 |
| 318| R-DFCIL: Relation-Guided Representation Learning for Data-Free Class Incremental Learning| ECCV | 2022| [code](https://github.com/jianzhangcs/r-dfcil)| 20|
| 319| Learning with Recoverable Forgetting | ECCV | 2022|| 12|
| 320| Long-Tailed Class Incremental Learning| ECCV | 2022|| 8.5 |
| 321| Novel Class Discovery without Forgetting| ECCV | 2022|| 14|
| 322| Class-incremental Novel Class Discovery | ECCV | 2022|| 15.5|
| 323| Few-Shot Class Incremental Learning From an Open-Set Perspective | ECCV | 2022|| 21.5|
| 324| Few-Shot Class-Incremental Learning via Entropy-Regularized Data-Free Replay| ECCV | 2022|| 23|
| 325| Online Continual Learning with Contrastive Vision Transformer| ECCV | 2022|| 13.5|
| 326| MgSvF: Multi-Grained Slow vs. Fast Framework for Few-Shot Class-Incremental Learning| TPAMI| 2022|| 28.5|
| 327| Class-Incremental Continual Learning into the eXtended DER-verse | TPAMI| 2022| [code](https://github.com/aimagelab/mammoth) | 39.5|
| 328| Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks| TPAMI| 2022| [code](https://github.com/zhoudw-zdw/TPAMI-Limit) | 28|
| 329| Continual Semi-Supervised Learning through Contrastive Interpolation Consistency | CVPR | 2022|| 9.5 |
| 330| Learning Bayesian Sparse Networks With Full Experience Replay for Continual Learning| CVPR | 2022|| 14|
| 331| Continual Learning With Lifelong Vision Transformer| CVPR | 2022|| 23|
| 332| Doodle It Yourself: Class Incremental Learning by Drawing a Few Sketches| CVPR | 2022|| 13.5|
| 333| Continual Learning for Visual Search with Backward Consistent Feature Embedding| CVPR | 2022|| 7.5 |
| 334| Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries| CVPR | 2022|| 15|
| 335| Not Just Selection, but Exploration: Online Class-Incremental Continual Learning via Dual View Consistency| CVPR | 2022|| 21.5|
| 336| Lifelong Graph Learning| CVPR | 2022|| 26.5|
| 337| Lifelong Unsupervised Domain Adaptive Person Re-identification with Coordinated Anti-forgetting and Adaptation | CVPR | 2022|| 9.5 |
| 338| vCLIMB: A Novel Video Class Incremental Learning Benchmark| CVPR | 2022|| 10|
| 339| Class-Incremental Learning by Knowledge Distillation with Adaptive Feature Consolidation| CVPR | 2022|| 59.5|
| 340| Few-Shot Incremental Learning for Label-to-Image Translation| CVPR | 2022|| 1|
| 341| MetaFSCIL: A Meta-Learning Approach for Few-Shot Class Incremental Learning | CVPR | 2022|| 39|
| 342| Incremental Learning in Semantic Segmentation from Image Labels| CVPR | 2022|| 19.5|
| 343| Learning to Imagine: Diversify Memory for Incremental Learning using Unlabeled Data| CVPR | 2022|| 12|
| 344| General Incremental Learning with Domain-aware Categorical Representations| CVPR | 2022|| 13|
| 345| Constrained Few-shot Class-incremental Learning| CVPR | 2022|| 46.5|
| 346| Overcoming Catastrophic Forgetting in Incremental Object Detection via Elastic Response Distillation| CVPR | 2022|| 27|
| 347| Meta-attention for ViT-backed Continual Learning | CVPR | 2022|| 12.5|
| 348| On Generalizing Beyond Domains in Cross-Domain Continual Learning| CVPR | 2022|| 12|
| 349| Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding | CVPR | 2022| [code](https://github.com/DQiaole/ZITS_inpainting)| 48|
| 350| Forward Compatible Few-Shot Class-Incremental Learning| CVPR | 2022| [code](https://github.com/zhoudw-zdw/CVPR22-Fact) | 66|
| 351| Federated Class-Incremental Learning | CVPR | 2022| [code](https://github.com/conditionWang/FCIL)| 43|
| 352| Representation Compensation Networks for Continual Semantic Segmentation| CVPR | 2022|| 33|
| 353| Effects of Auxiliary Knowledge on Continual Learning| ICPR | 2022|| 2.5 |
| 354| Continual Sequence Generation with Adaptive Compositional Modules| ACL| 2022|| 10.5|
| 355| Learngene: From Open-World to Your Learning Task | AAAI | 2022| [code](https://github.com/BruceQFWang/learngene)| 4.5 |
| 356| Rethinking the Representational Continuity: Towards Unsupervised Continual Learning| ICLR | 2022|| 1|
| 357| Looking Back on Learned Experiences For Class/task Incremental Learning | ICLR | 2022|| 15.5|
| 358| Continual Normalization: Rethinking Batch Normalization for Online Continual Learning | ICLR | 2022|| 21.5|
| 359| Learning curves for continual learning in neural networks: Self-knowledge transfer and forgetting| ICLR | 2022|| 4.5 |
| 360| Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System| ICLR | 2022|| 44|
| 361| Pretrained Language Model in Continual Learning: A Comparative Study | ICLR | 2022|| 26.5|
| 362| Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference| ICLR | 2022|| 20.5|
| 363| New Insights on Reducing Abrupt Representation Change in Online Continual Learning | ICLR | 2022|| 58.5|
| 364| Towards Continual Knowledge Learning of Language Models | ICLR | 2022|| 41|
| 365| CLEVA-Compass: A Continual Learning Evaluation Assessment Compass to Promote Research Transparency and Comparability| ICLR | 2022|| 15.5|
| 366| CoMPS: Continual Meta Policy Search| ICLR | 2022|| 7.5 |
| 367| Information-theoretic Online Memory Selection for Continual Learning | ICLR | 2022|| 18|
| 368| Subspace Regularizers for Few-Shot Class Incremental Learning| ICLR | 2022|| 20|
| 369| LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5| ICLR | 2022|| 26.5|
| 370| Class-incremental learning: survey and performance evaluation| TPAMI| 2022| [code](https://github.com/mmasana/FACIL)| 229.5 |
| 371| Uncertainty-guided semi-supervised few-shot class-incremental learning with knowledge distillation| MM | 2022|||
| 372| Ss-il: Separated softmax for incremental learning| ICCV | 2021|| 51|
| 373| Rainbow memory: Continual learning with a memory of diverse samples| CVPR | 2021|| 80.67 |
| 374| Contrastive continual learning| ICCV | 2021|| 82.33 |
| 375| Using hindsight to anchor past knowledge in continual learning | AAAI | 2021|| 63.33 |
| 376| Distilling causal effect of data in class-incremental learning | CVPR | 2021|| 57.33 |
| 377| Gradient-based editing of memory examples for online task-free continual learning| NeurIPS | 2021|| 24|
| 378| Online class-incremental continual learning with adversarial shapley value| AAAI | 2021| [code](https://github.com/RaptorMai/online-continual-learning)| 48.67 |
| 379| On learning the geodesic path for incremental learning| CVPR | 2021|| 30.67 |
| 380| Layerwise optimization by gradient decomposition for continual learning | CVPR | 2021|| 17.67 |
| 381| Rehearsal revealed: The limits and merits of revisiting samples in continual learning | ICCV | 2021|| 23.33 |
| 382| Ordisco: Effective and efficient usage of incremental unlabeled data for semi-supervised continual learning| CVPR | 2021|| 20|
| 383| Afec: Active forgetting of negative transfer in continual learning | NeurIPS | 2021|| 15|
| 384| Memory replay with data compression for continual learning| ICLR | 2021|| 23|
| 385| Online coreset selection for rehearsal-based continual learning| ICLR | 2021|| 34.67 |
| 386| Flattening sharpness for dynamic gradient projection memory benefits continual learning | NeurIPS | 2021|| 15|
| 387| Optimizing reusable knowledge for continual learning via metalearning| NeurIPS | 2021|| 9|
| 388| Natural continual learning: success is a journey, not (just) a destination| NeurIPS | 2021|| 13.33 |
| 389| Trgp: Trust region gradient projection for continual learning| ICLR | 2021|| 15.33 |
| 390| Continual learning with recursive gradient optimization | ICLR | 2021|| 8.33|
| 391| Representational continuity for unsupervised continual learning| ICLR | 2021|| 30.67 |
| 392| Effect of scale on catastrophic forgetting in neural networks| ICLR | 2021|| 34.67 |
| 393| Training networks in null space of feature covariance for continual learning| CVPR | 2021|| 28|
| 394| How well does self-supervised pre-training perform with streaming data? | ICLR | 2021|| 6.67|
| 395| Co2l: Contrastive continual learning | ICCV | 2021|| 82.33 |
| 396| Dualnet: Continual learning, fast and slow| NeurIPS | 2021|| 36.67 |
| 397| Posterior meta-replay for continual learning | NeurIPS | 2021|| 15.33 |
| 398| Bayesian structural adaptation for continual learning | ICML | 2021|| 8.33|
| 399| Continual learning with filter atom swapping | ICLR | 2021|| 7|
| 400| Continual learning via local module composition| NeurIPS | 2021|| 16.67 |
| 401| Bns: Building network structures dynamically for continual learning| NeurIPS | 2021|| 9.33|
| 402| Model zoo: A growing brain that learns continually | ICLR | 2021|| 13|
| 403| Incremental Object Detection via Meta-Learning | NueraIPS| 2021| [code](https://github.com/JosephKJ/iOD) | 29.33 |
| 404| A Procedural World Generation Framework for Systematic Evaluation of Continual Learning | NueraIPS| 2021|| 2|
| 405| Class-Incremental Learning via Dual Augmentation | NueraIPS| 2021|| 33|
| 406| SSUL: Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning | NueraIPS| 2021|| 16.33 |
| 407| RMM: Reinforced Memory Management for Class-Incremental Learning | NueraIPS| 2021|| 22.67 |
| 408| Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima | NueraIPS| 2021|| 30|
| 409| Lifelong Domain Adaptation via Consolidated Internal Distribution| NueraIPS| 2021|| 17.33 |
| 410| Formalizing the Generalization-Forgetting Trade-off in Continual Learning | NueraIPS| 2021|| 8.33|
| 411| Learning where to learn: Gradient sparsity in meta and continual learning | NueraIPS| 2021|| 15.67 |
| 412| Continual Auxiliary Task Learning| NueraIPS| 2021|| 1.67|
| 413| Mitigating Forgetting in Online Continual Learning with Neuron Calibration| NueraIPS| 2021|| 11.33 |
| 414| BNS: Building Network Structures Dynamically for Continual Learning| NueraIPS| 2021|| 9.33|
| 415| BooVAE: Boosting Approach for Continual Learning of VAE | NueraIPS| 2021|| 7.67|
| 416| Generative vs. Discriminative: Rethinking The Meta-Continual Learning| NueraIPS| 2021|| 4.67|
| 417| Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning| NueraIPS| 2021|| 24.33 |
| 418| Bridging Non Co-occurrence with Unlabeled In-the-wild Data for Incremental Object Detection| NueraIPS| 2021| [code](https://github.com/dongnana777/Bridging-Non-Co-occurrence) | 6.33|
| 419| Striking a Balance between Stability and Plasticity for Class-Incremental Learning | ICCV | 2021|| 15|
| 420| Synthesized Feature based Few-Shot Class-Incremental Learning on a Mixture of Subspaces | ICCV | 2021|| 18.67 |
| 421| Class-Incremental Learning for Action Recognition in Videos | ICCV | 2021|| 12.33 |
| 422| Continual Prototype Evolution:Learning Online from Non-Stationary Data Streams| ICCV | 2021|| 54.67 |
| 423| Wanderlust: Online Continual Object Detection in the Real World| ICCV | 2021|| 1|
| 424| Continual Learning on Noisy Data Streams via Self-Purified Replay| ICCV | 2021|| 9.67|
| 425| Else-Net: Elastic Semantic Network for Continual Action Recognition from Skeleton Data| ICCV | 2021|| 13.67 |
| 426| Detection and Continual Learning of Novel Face Presentation Attacks| ICCV | 2021|| 12|
| 427| Online Continual Learning with Natural Distribution Shifts: An Empirical Study with Visual Data| ICCV | 2021|| 19.67 |
| 428| Continual Learning for Image-Based Camera Localization| ICCV | 2021|| 6.67|
| 429| Generalized and Incremental Few-Shot Learning by Explicit Learning and Calibration without Forgetting | ICCV | 2021|| 14.67 |
| 430| Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning | ICCV | 2021|| 46|
| 431| RECALL: Replay-based Continual Learning in Semantic Segmentation | ICCV | 2021|| 32|
| 432| Few-Shot and Continual Learning with Attentive Independent Mechanisms| ICCV | 2021|| 8|
| 433| Learning with Selective Forgetting | IJCAI| 2021|| 8.67|
| 434| Continuous Coordination As a Realistic Scenario for Lifelong Learning| ICML | 2021|| 11.33 |
| 435| Kernel Continual Learning | ICML | 2021|| 10.33 |
| 436| Variational Auto-Regressive Gaussian Processes for Continual Learning| ICML | 2021|| 7|
| 437| Continual Learning in the Teacher-Student Setup: Impact of Task Similarity| ICML | 2021|| 15|
| 438| Federated Continual Learning with Weighted Inter-client Transfer | ICML | 2021|| 43|
| 439| Towards Open World Object Detection| CVPR | 2021| [code](https://github.com/JosephKJ/OWOD)| 127 |
| 440| Prototype Augmentation and Self-Supervision for Incremental Learning | CVPR | 2021| [code](https://github.com/Impression2805/CVPR21_PASS)| 77|
| 441| Incremental Learning via Rate Reduction | CVPR | 2021|| 10.33 |
| 442| IIRC: Incremental Implicitly-Refined Classification| CVPR | 2021|| 11|
| 443| Continual Adaptation of Visual Representations via Domain Randomization and Meta-learning| CVPR | 2021|| 21.67 |
| 444| Image De-raining via Continual Learning | CVPR | 2021|| 16.33 |
| 445| Continual Learning via Bit-Level Information Preserving | CVPR | 2021|| 11.67 |
| 446| Hyper-LifelongGAN: Scalable Lifelong Learning for Image Conditioned Generation| CVPR | 2021|| 13.33 |
| 447| Lifelong Person Re-Identification via Adaptive Knowledge Accumulation| CVPR | 2021|| 19|
| 448| Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning| CVPR | 2021|| 39.33 |
| 449| Adaptive Aggregation Networks for Class-Incremental Learning| CVPR | 2021|| 60.67 |
| 450| Incremental Few-Shot Instance Segmentation| CVPR | 2021|| 21|
| 451| Efficient Feature Transformations for Discriminative and Generative Continual Learning| CVPR | 2021|| 20|
| 452| Few-Shot Incremental Learning with Continually Evolved Classifiers | CVPR | 2021|| 72.67 |
| 453| Rectification-based Knowledge Retention for Continual Learning | CVPR | 2021|| 14|
| 454| DER: Dynamically Expandable Representation for Class Incremental Learning | CVPR | 2021|| 129.33|
| 455| Semantic-aware Knowledge Distillation for Few-Shot Class-Incremental Learning | CVPR | 2021|| 51.33 |
| 456| PLOP: Learning without Forgetting for Continual Semantic Segmentation| CVPR | 2021|| 60|
| 457| Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations| CVPR | 2021|| 40.67 |
| 458| Lifelong and Continual Learning Dialogue Systems: Learning during Conversation| AAAI | 2021|| 15.67 |
| 459| Continual learning for named entity recognition| AAAI | 2021|| 19.33 |
| 460| Split-and-Bridge: Adaptable Class Incremental Learning within a Single Neural Network | AAAI | 2021| [code](https://github.com/bigdata-inha/Split-and-Bridge) | 6.67|
| 461| Curriculum-Meta Learning for Order-Robust Continual Relation Extraction | AAAI | 2021|| 16.67 |
| 462| Continual Learning by Using Information of Each Class Holistically | AAAI | 2021|| 17.33 |
| 463| Gradient Regularized Contrastive Learning for Continual Domain Adaptation | AAAI | 2021|| 13|
| 464| Unsupervised Model Adaptation for Continual Semantic Segmentation| AAAI | 2021|| 20.33 |
| 465| A Continual Learning Framework for Uncertainty-Aware Interactive Image Segmentation| AAAI | 2021|| 7.67|
| 466| A continual learning survey: Defying forgetting in classification tasks | TPAMI| 2021|| 464.67|
| 467| Recent Advances of Continual Learning in Computer Vision: An Overview| Arxiv| 2021|| 18|
| 468| Continual Learning of Natural Language Processing Tasks: A Survey| Arxiv| 2021|| 10|
| 469| Deep continual learning for emerging emotion recognition| MM | 2021|||
| 470| Deep auto-encoders with sequential learning for multimodal dimensional emotion recognition | MM | 2021|||
| 471| Video transformer for deepfake detection with incremental learning | MM | 2021|||
| 472| Remember and reuse: Cross-task blind image quality assessment via relevance-aware incremental learning| MM | 2021|||
| 473| Continual learning with extended kronecker-factored approximate curvature | CVPR | 2020|| 9.25|
| 474| Generalized variational continual learning| ICLR | 2020|| 12|
| 475| Overcoming catastrophic forgetting by neuron-level plasticity control| AAAI | 2020|| 8.25|
| 476| Continual learning with node-importance based adaptive group sparse regularization | NeruIPS | 2020|| 21|
| 477| Memory-efficient incremental learning through feature adaptation | ECCV | 2020|| 35.25 |
| 478| Podnet: Pooled outputs distillation for small-tasks incremental learning| ECCV | 2020| [code](https://github.com/arthurdouillard/incremental_learning.pytorch)| 130.75|
| 479| Dark experience for general continual learning: a strong, simple baseline | NeruIPS | 2020| [code](https://github.com/aimagelab/mammoth) | 145.75|
| 480| Continual deep learning by functional regularisation of memorable past| NeruIPS | 2020|| 29.5|
| 481| Eec: Learning to encode and regenerate images for continual learning | ICLR | 2020|| 11.25 |
| 482| Coresets via bilevel optimization for continual learning and streaming| NeurIPS | 2020|| 45|
| 483| Online learned continual compression with adaptive quantization modules | ICML | 2020|| 16.5|
| 484| Gan memory with no forgetting | NeurIPS | 2020|| 26|
| 485| Remembering for the right reasons: Explanations reduce catastrophic forgetting| ICLR | 2020|| 10.75 |
| 486| Remind your neural network to prevent catastrophic forgetting| ECCV | 2020|| 64|
| 487| Mnemonics training: Multi-class incremental learning without forgetting | CVPR | 2020| [code](https://github.com/yaoyao-liu/mnemonics) | 78.5|
| 488| Gradient projection memory for continual learning| ICLR | 2020|| 68.67 |
| 489| Learning latent representations across multiple data domains using lifelong VAEGAN | ECCV | 2020|| 15.5|
| 490| Semantic drift compensation for class-incremental learning| CVPR | 2020| [code](https://github.com/yulu0724/SDC-IL) | 66.25 |
| 491| Maintaining discrimination and fairness in class incremental learning| CVPR | 2020|| 89.25 |
| 492| Online fast adaptation and knowledge accumulation (osaka): a new approach to continual learning| NeurIPS | 2020|| 18|
| 493| Continual learning in low-rank orthogonal subspaces| NeurIPS | 2020|| 22.75 |
| 494| Look-ahead meta learning for continual learning| NeurIPS | 2020|| 26.5|
| 495| Meta-consolidation for continual learning | NeurIPS | 2020|| 12.5|
| 496| Linear mode connectivity in multitask and continual learning| ICLR | 2020|| 23|
| 497| Understanding the role of training regimes in continual learning | NeurIPS | 2020|| 43|
| 498| What is being transferred in transfer learning?| NeurIPS | 2020|| 99.25 |
| 499| itaml: An incremental task-agnostic meta-learning approach| CVPR | 2020| [code](https://github.com/brjathu/iTAML)| 38.25 |
| 500| Sharpness-aware minimization for efficiently improving generalization| ICLR | 2020|| 249.25|
| 501| Side-tuning: a baseline for network adaptation via additive side networks | ECCV | 2020|| 34.25 |
| 502| On leveraging pretrained gans for generation with limited data | ICML | 2020|| 22.25 |
| 503| Adversarial continual learning| ECCV | 2020| [code](https://github.com/facebookresearch/Adversarial-Continual-Learning) | 45|
| 504| Reparameterizing convolutions for incremental multi-task learning without task interference| ECCV | 2020|| 17.25 |
| 505| Conditional channel gated networks for task-aware continual learning | CVPR | 2020|| 47.5|
| 506| Calibrating cnns for lifelong learning| NeurIPS | 2020|| 17|
| 507| Efficient continual learning with modular networks and task-driven priors | ICLR | 2020|| 20.25 |
| 508| Supermasks in superposition | NeurIPS | 2020|| 58|
| 509| Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks| NeurIPS | 2020| [code](https://github.com/ZixuanKe/CAT) | 26.75 |
| 510| RATT: Recurrent Attention to Transient Tasks for Continual Image Captioning | NeurIPS | 2020|| 10.25 |
| 511| Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization| NeurIPS | 2020|| 8|
| 512| REMIND Your Neural Network to Prevent Catastrophic Forgetting| ECCV | 2020| [code](https://github.com/tyler-hayes/REMIND)| 64|
| 513| Incremental Meta-Learning via Indirect Discriminant Alignment| ECCV | 2020|| 6.5 |
| 514| Learning latent representions across multiple data domains using Lifelong VAEGAN | ECCV | 2020|| 15.5|
| 515| Online Continual Learning under Extreme Memory Constraints| ECCV | 2020|| 16|
| 516| Class-Incremental Domain Adaptation| ECCV | 2020|| 12|
| 517| More Classifiers, Less Forgetting: A Generic Multi-classifier Paradigm for Incremental Learning| ECCV | 2020|| 20.25 |
| 518| Piggyback GAN: Efficient Lifelong Learning for Image Conditioned Generation | ECCV | 2020|| 8.5 |
| 519| GDumb: A Simple Approach that Questions Our Progress in Continual Learning| ECCV | 2020|| 117 |
| 520| Imbalanced Continual Learning with Partitioning Reservoir Sampling | ECCV | 2020|| 22.25 |
| 521| Topology-Preserving Class-Incremental Learning | ECCV | 2020|| 39|
| 522| XtarNet: Learning to Extract Task-Adaptive Representation for Incremental Few-Shot Learning| ICML | 2020|| 13.25 |
| 523| Optimal Continual Learning has Perfect Memory and is NP-HARD| ICML | 2020|| 24.25 |
| 524| Few-Shot Class-Incremental Learning| CVPR | 2020|| 88.25 |
| 525| Modeling the Background for Incremental Learning in Semantic Segmentation | CVPR | 2020|| 60.25 |
| 526| Incremental Few-Shot Object Detection| CVPR | 2020|| 61|
| 527| Incremental Learning In Online Scenario | CVPR | 2020|| 32.75 |
| 528| iTAML : An Incremental Task-Agnostic Meta-learning Approach | CVPR | 2020|| 38.25 |
| 529| Scalable and Order-robust Continual Learning with Additive Parameter Decomposition | ICLR | 2020|| 32.75 |
| 530| Uncertainty-guided Continual Learning with Bayesian Neural Networks| ICLR | 2020|| 53|
| 531| A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning | ICLR | 2020|| 52|
| 532| Compositional Continual Language Learning | ICLR | 2020|| 1.5 |
| 533| LAMOL: LAnguage MOdeling for Lifelong Language Learning | ICLR | 2020|| 43.75 |
| 534| Rethinking Experience Replay: A Bag of Tricks for Continual Learning | ICPR | 2020|| 38|
| 535| Unsupervised Model Personalization While Preserving Privacy and Scalability: An Open Problem | CVPR | 2020|| 6.75|
| 536| Neural Topic Modeling with Continual Lifelong Learning| ICML | 2020|| 9.25|
| 537| Continual learning by asymmetric loss approximation with single-side overestimation| ICCV | 2019|| 7|
| 538| Continual learning with adaptive weights (claw)| ICLR | 2019|| 14|
| 539| Learning without memorizing | CVPR | 2019|| 91|
| 540| Learning a unified classifier incrementally via rebalancing | CVPR | 2019| [code](https://github.com/hshustc/CVPR19_Incremental_Learning)| 195.8 |
| 541| Lifelong gan: Continual learning for conditional image generation| ICCV | 2019|| 36.8|
| 542| Overcoming catastrophic forgetting with unlabeled data in the wild | ICCV | 2019|| 38.8|
| 543| Functional regularisation for continual learning with gaussian processes| ICLR | 2019|| 30.6|
| 544| Online continual learning with maximal interfered retrieval | NeurIPS | 2019|| 94.2|
| 545| Gradient based sample selection for online continual learning| NeurIPS | 2019|| 139 |
| 546| Scalable recollections for continual lifelong learning| AAAI | 2019|| 13.2|
| 547| Uncertainty-based continual learning with adaptive regularization| NeurIPS | 2019|| 34.4|
| 548| Overcoming catastrophic forgetting for continual learning via model adaptation| CVPR | 2019|| 30.4|
| 549| Continual learning with hypernetworks| ICLR | 2019|| 69.6|
| 550| Scalable and order-robust continual learning with additive parameter decomposition | ICLR | 2019|| 26.2|
| 551| Continual Learning with Bayesian Neural Networks for Non-Stationary Data| ICLR | 2019|| 13.4|
| 552| Compacting, Picking and Growing for Unforgetting Continual Learning| NeurIPS | 2019| [code](https://github.com/ivclab/CPG) | 49.2|
| 553| Increasingly Packing Multiple Facial-Informatics Modules in A Unified Deep-Learning Model via Lifelong Learning| MM | 2019| [code](https://github.com/ivclab/PAE) | 9|
| 554| Complementary Learning for Overcoming Catastrophic Forgetting Using Experience Replay | IJCAI| 2019|| 14.4|
| 555| IL2M: Class Incremental Learning With Dual Memory| ICCV | 2019|| 63|
| 556| Incremental Learning Using Conditional Adversarial Networks | ICCV | 2019|| 29.4|
| 557| RPSNet: Random Path Selection for Incremental Learning| NeurIPS | 2019|| 43.6|
| 558| Meta-Learning Representations for Continual Learning| NeurIPS | 2019| [code](https://github.com/Khurramjaved96/mrcl)| 63.6|
| 559| Large Scale Incremental Learning| CVPR | 2019|| 222.4 |
| 560| Learning to Remember: A Synaptic Plasticity Driven Framework for Continual Learning| CVPR | 2019|| 54.8|
| 561| Task-Free Continual Learning| CVPR | 2019|| 60.2|
| 562| Learn to Grow: A Continual Structure Learning Framework for Overcoming Catastrophic Forgetting | ICML | 2019|| 71.8|
| 563| Efficient Lifelong Learning with A-GEM| ICLR | 2019| [code](https://github.com/facebookresearch/agem)| 247.4 |
| 564| Learning to Learn without Forgetting By Maximizing Transfer and Minimizing Interference | ICLR | 2019| [code](https://github.com/mattriemer/mer)| 138.2 |
| 565| Overcoming Catastrophic Forgetting via Model Adaptation | ICLR | 2019|| 30.4|
| 566| A comprehensive, application-oriented study of catastrophic forgetting in DNNs| ICLR | 2019|| 18.2|
| 567| Incremental Stochastic Factorization for Online Reinforcement Learning| AAAI | 2019|| 1.8 |
| 568| Progress & compress: A scalable framework for continual learning | ICML | 2018|| 136.17|
| 569| Rotate your networks: Better weight consolidation and less catastrophic forgetting | ICPR | 2018|| 40.5|
| 570| Variational continual learning| ICLR | 2018|| 120.33|
| 571| Memory replay gans: Learning to generate new categories without forgetting| NeruIPS | 2018|| 66.17 |
| 572| Lifelong learning via progressive distillation and retrospection | ECCV | 2018|| 32.67 |
| 573| Fearnet: Brain-inspired model for incremental learning| ICLR | 2018|| 82.33 |
| 574| Lifelong learning with dynamically expandable networks| ICLR | 2018|| 188.83|
| 575| Memory Replay GANs: learning to generate images from new categories without forgetting| NuraIPS | 2018| [code]() | 2.67|
| 576| Reinforced Continual Learning | NuraIPS | 2018| [code](https://github.com/xujinfan/Reinforced-Continual-Learning) | 56.67 |
| 577| Online Structured Laplace Approximations for Overcoming Catastrophic Forgetting| NuraIPS | 2018|| 47.17 |
| 578| Rotate your Networks: Better Weight Consolidation and Less Catastrophic Forgetting (R-EWC) | ICPR | 2018| [code](https://github.com/xialeiliu/RotateNetworks)| 40.5|
| 579| End-to-End Incremental Learning | ECCV | 2018| [code](https://github.com/fmcp/EndToEndIncrementalLearning)| 186 |
| 580| Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence| ECCV | 2018|| 169.17|
| 581| Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights | ECCV | 2018| [code](https://github.com/arunmallya/piggyback) | 102.83|
| 582| Memory Aware Synapses: Learning what (not) to forget| ECCV | 2018| [code](https://github.com/rahafaljundi/MAS-Memory-Aware-Synapses) | 231.5 |
| 583| PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning | CVPR | 2018| [code](https://github.com/arunmallya/packnet)| 189.67|
| 584| Overcoming Catastrophic Forgetting with Hard Attention to the Task | ICML | 2018| [code](https://github.com/joansj/hat) | 163.83|
| 585| Incremental Learning Framework for Indoor Scene Recognition | AAAI | 2018|| 3|
| 586| HOUDINI: Lifelong Learning as Program Synthesis| NeurIPS | 2018|| 14.17 |
| 587| Overcoming catastrophic forgetting by incremental moment matching| NeruIPS | 2017|| 90.86 |
| 588| Learning without forgetting | PAMI | 2017|| 549.14|
| 589| Encoder based lifelong learning | ICCV | 2017|| 48.86 |
| 590| Gradient episodic memory for continual learning| NeurIPS | 2017|| 337.86|
| 591| Continual learning with deep generative replay | NeurIPS | 2017|| 267.71|
| 592| Neural discrete representation learning | NeurIPS | 2017|| 481 |
| 593| Continual Learning Through Synaptic Intelligence | ICML | 2017| [code](https://github.com/ganguli-lab/pathint)| 346.29|
| 594| Incremental Learning of Object Detectors Without Catastrophic Forgetting| ICCV | 2017|| 73.29 |
| 595| iCaRL: Incremental Classifier and Representation Learning | CVPR | 2017| [code](https://github.com/srebuffi/iCaRL)| 482.86|
| 596| Fast online incremental learning on mixture streaming data| AAAI | 2017|| 2|
| 597| A deep hierarchical approach to lifelong learning in minecraft | AAAI | 2017|| 60.43 |
| 598| Lifelong learning of action representations with deep neural self-organization| AAAI | 2017|| 1.71|
| 599| Expert Gate: Lifelong Learning with a Network of Experts| CVPR | 2017|| 87.71 |
| 600| Using Task Features for Zero-Shot Knowledge Transfer in Lifelong Learning | IJCAI| 2016|| 13.38 |
| 601| Dual-Memory Deep Learning Architectures for Lifelong Learning of Everyday Human Behaviors| IJCAI| 2016|| 7.25|
| 602| Progressive neural networks | ICML | 2016|| 349 |
| 603| Error-driven incremental learning in deep convolutional neural network for large-scale image classification| MM | 2014|| 30.9|
| 604| Lifelong machine learning systems: Beyond learning algorithms| AAAI | 2013|| 37.91 |
| 605| Active task selection for lifelong machine learning| AAAI | 2013|| 7.73|
| 606| Recurrent transition hierarchies for continual learning: A general overview | AAAI | 2011||0|
## 4. License
This repository is released under the [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).
